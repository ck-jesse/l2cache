#server:
#servlet:
#  context-path: /l2cache-example

logging:
  level:
    root: info
    # 日志级别指定到包或类
    com.github.jesse.l2cache: debug

spring:
  application:
    name: l2cache-example

# ====================================== #
# 以下配置，支持不同缓存维度的缓存配置（按需配置）
# ====================================== #

# 二级缓存配置
# 注：caffeine 不适用于数据量大，并且缓存命中率极低的业务场景，如用户维度的缓存。请慎重选择。
l2cache:
  config:
    # Redisson 的yaml配置文件
    redissonYamlConfig: redisson.yaml
    # 默认缓存配置
    defaultConfig:
      # 是否存储空值，默认true，防止缓存穿透
      allowNullValues: true
      # 空值过期时间，单位秒
      nullValueExpireTimeSeconds: 30
      # 是否使用一级缓存的过期时间来替换二级缓存的过期时间，默认true，简化缓存配置
      useL1ReplaceL2ExpireTime: true
      # 缓存类型
      cacheType: COMPOSITE
      # 组合缓存配置
      composite:
        # 一级缓存类型
        l1CacheType: caffeine
        # 二级缓存类型
        l2CacheType: redis
        # 二级缓存是否通过batchPut()来处理缓存数据，默认false
        l2BatchPut: true
        # 二级缓存是否通过batchEvict()来处理缓存数据，默认false
        l2BatchEvict: true
        # 是否全部启用一级缓存，默认false
        l1AllOpen: false
        # 是否手动启用一级缓存，默认false
        l1Manual: true
        # 手动配置走一级缓存的缓存key集合，针对单个key维度
        l1ManualKeySet:
          - userCache:user01
          - userCache:user02
          - userCache:user03
          - userCache:user04
        # 手动配置走一级缓存的缓存名字集合，针对cacheName维度
        l1ManualCacheNameSet:
          - newBrandCache
          - newGoodsPriceRevisionCache
      # 一级缓存
      caffeine:
        # 创建缓存的默认配置（格式完全与Caffeine配置一致）
        defaultSpec: initialCapacity=10,maximumSize=2,refreshAfterWrite=30m,softValues,recordStats
        # 设置指定缓存名的创建缓存配置(如：userCache为缓存名称)
        specs:
          userCache: initialCapacity=10,maximumSize=200,refreshAfterWrite=2m,recordStats
          newBrandCache: initialCapacity=64,maximumSize=5000,refreshAfterWrite=2h,recordStats
          newGoodsPriceRevisionCache: initialCapacity=64,maximumSize=10000,refreshAfterWrite=1d,recordStats
          # cacheName中含有: / * 等特殊字符，需要加 "[ ]"
          "[userCache:v1]": initialCapacity=64,maximumSize=10000,refreshAfterWrite=60m,recordStats
      # 二级缓存
      redis:
        # 加载数据时，是否加锁，默认false
        lock: false
        # 加锁时，true调用tryLock()，false调用lock()
        tryLock: true
        # 批量操作的大小，可以理解为是分页，默认50
        batchPageSize: 3
        # 默认缓存过期时间(ms)
        expireTime: 86400000
        # 针对cacheName维度的过期时间集合，单位ms
        expireTimeCacheNameMap:
          brandCache: 86400000
    # 缓存配置集合（针对cacheName的个性化缓存配置），按需配置
    configMap:
      # 样例：指定某个缓存维度走caffeine
      brandCache:
        # 缓存类型
        cacheType: caffeine
        # 一级缓存
        caffeine:
          # 创建缓存的默认配置
          defaultSpec: initialCapacity=10,maximumSize=2,refreshAfterWrite=30m,softValues,recordStats
      # 样例：指定某个缓存维度走redis
      goodsPriceRevisionCache:
        # 缓存类型
        cacheType: redis
        # 二级缓存
        redis:
          # 加载数据时，是否加锁
          lock: false
          # 加锁时，true调用tryLock()，false调用lock()
          tryLock: true
          # 批量操作的大小，可以理解为是分页
          batchPageSize: 3
          # 默认缓存过期时间(ms)
          expireTime: 86400000
          # 针对cacheName维度的过期时间集合，单位ms
          expireTimeCacheNameMap:
            brandCache: 86400000
    # 缓存同步策略配置
    cacheSyncPolicy:
      # 策略类型 kafka / redis，推荐使用redis
      type: redis
      # 缓存更新时通知其他节点的topic名称
      topic: l2cache
      # 具体的属性配置，不同的类型配置各自的属性即可(自定义和原生的都可以)
      #props:
      #  # kafka properties config
      #  bootstrap.servers: localhost:9092
      #  # 生产者id
      #  client.id: L2CacheProducer
      #  # 发送消息的确认机制
      #  acks: 1
      #  # key序列化处理器
      #  key.serializer: org.apache.kafka.common.serialization.StringSerializer
      #  # value序列化处理器
      #  value.serializer: org.apache.kafka.common.serialization.StringSerializer
      #  # 消费者groupid
      #  # 因为是缓存同步，所以必须让所有消费者都消费到相同的消息。采用动态生成一个id附加到配置的group.id上，实现每个consumer都是一个group，来实现发布订阅的模式。
      #  group.id: L2CacheConsumerGroup
      #  # 自动提交offset（默认true）
      #  enable.auto.commit: true
      #  # 自动提交间隔
      #  auto.commit.interval.ms: 1000
      #  # key反序列化处理器
      #  key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
      #  # value反序列化处理器
      #  value.deserializer: org.apache.kafka.common.serialization.StringDeserializer
      #  # 设置消费的位置
      #  auto.offset.reset: latest
      #  # 设置一次最大拉取的消息条数（默认500）
      #  max.poll.records: 10
      #  # 设置poll最大时间间隔（默认3s）
      #  max.poll.interval.ms: 3000
    # 热key探测
    hotkey:
      # 热key探测类型,支持 none、jd、sentinel，目前 sentinel 仅支持单机，默认为 none，不启用热key探测。
      type: sentinel
      sentinel:
        # 若配置了默认规则，针对所有的cacheName，生成其默认的热点参数规则，简化配置
        # 若未配置默认规则，则仅针对 rules 中的配置进行热点参数探测
        # 注：规则具体的配置是针对ParamFlowRule的配置
        default-rule:
          grade: 1
          param-idx: 0
          count: 6
          durationInSec: 1
        rules:
          # 案例1
          # resourceName 资源名称，通常设置为缓存名称
          - resource: newBrandCache
            # 流量控制的阈值类型，0表示线程数，1表示qps，默认1
            grade: 1
            # 参数下标
            paramIdx: 0
            # 阈值计数
            count: 3
            # 统计窗口时间长度（单位为秒），默认为1
            durationInSec: 5
          # 案例2
          - resource: newGoodsPriceRevisionCache
            count: 5
      # jd:
      # serviceName: weeget-bullet-goods-rest
      # #etcd的地址，如有多个用逗号分隔
      # etcdUrl: http://127.0.0.1:2379