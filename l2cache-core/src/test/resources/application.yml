server:
  port: 8081
  #servlet:
  #  context-path: /l2cache-example

logging:
  level:
    root: info
    # 日志级别指定到包或类
    com.github.jesse.l2cache: debug

spring:
  application:
    name: l2cache-example
  # spring boot redis配置
  redis:
    timeout: 3000
    host: 127.0.0.1
    port: 6379
    password:

# 二级缓存配置
l2cache:
  config:
    # 是否存储空值，默认true，防止缓存穿透
    allowNullValues: true
    # 缓存类型
    cacheType: composite
    # 组合缓存配置
    composite:
      # 一级缓存类型
      l1CacheType: caffeine
      # 二级缓存类型
      l2CacheType: redis
      # 是否全部启用一级缓存，默认false
      l1AllOpen: false
      # 是否手动启用一级缓存，默认false
      l1Manual: true
      # 手动配置走一级缓存的缓存key集合，针对单个key维度
      l1ManualKeySet:
        - a
        - "[actLimitMarkupCache:11_2]"
        - "[actLimitMarkupCache:11_3]"
      # 手动配置走一级缓存的缓存名字集合，针对cacheName维度
      l1ManualCacheNameSet:
        - compositeCache
        - goodsSpecCache


    # 一级缓存
    caffeine:
      # 是否自动刷新过期缓存 true 是 false 否
      autoRefreshExpireCache: true
      # 缓存刷新调度线程池的大小
      refreshPoolSize: 1
      # 缓存刷新的频率(秒)
      refreshPeriod: 5
      # 高并发场景下建议使用refreshAfterWrite，在缓存过期后不会被回收，再次访问时会去刷新缓存，在新值没有加载完毕前，其他的线程访问始终返回旧值
      # Caffeine在缓存过期时默认只有一个线程去加载数据，配置了refreshAfterWrite后当大量请求过来时，可以确保其他用户快速获取响应。
      # 创建缓存的默认配置（完全与SpringCache中的Caffeine实现的配置一致）
      # 如果expireAfterWrite和expireAfterAccess同时存在，以expireAfterWrite为准。
      # 最新最优的推荐用法：refreshAfterWrite 和 实现CacheService接口，只需实现4个业务相关的方法即可（缓存操作提炼到上层接口中去实现）
      # 基于注解的推荐用法：refreshAfterWrite 和 实现CacheService接口，并定义@Cacheable(sync=true)
      defaultSpec: initialCapacity=10,maximumSize=200,refreshAfterWrite=30s,recordStats
      # 设置指定缓存名的创建缓存配置(如：userCache为缓存名称)
      specs:
        userCache: initialCapacity=10,maximumSize=200,expireAfterWrite=30s
        userCacheSync: initialCapacity=10,maximumSize=200,refreshAfterWrite=30s,recordStats
    # 二级缓存
    redis:
      # 加载数据时，是否加锁
      lock: false
      # 加载数据时是调用tryLock()，还是lock()，true表示使用tryLock()
      tryLock: true
      # 缓存过期时间(ms)
      expireTime: 30000
      # 是否启用副本，以redis内存空间来降低单分片压力
      duplicate: true
      # 默认副本数量
      defaultDuplicateSize: 3
      # 副本缓存key集合，针对单个key维度
      duplicateKeyMap:
        redisCache:key_loader123: 3
      # 副本缓存名字集合，针对cacheName维度
      duplicateCacheNameMap:
        redisCache: 3
      # Redisson 的yaml配置文件
      redissonYamlConfig: redisson.yaml
      # 缓存同步策略配置
    cacheSyncPolicy:
      # 策略类型
      type: kafka
      # 缓存更新时通知其他节点的topic名称
      topic: l2cache
      # 具体的属性配置，不同的类型配置各自的属性即可(自定义和原生的都可以)
      props:
        # kafka properties config
        bootstrap.servers: localhost:9092
        # 生产者id
        client.id: L2CacheProducer
        # 发送消息的确认机制
        acks: 1
        # key序列化处理器
        key.serializer: org.apache.kafka.common.serialization.StringSerializer
        # value序列化处理器
        value.serializer: org.apache.kafka.common.serialization.StringSerializer
        # 消费者groupid
        # 因为是缓存同步，所以必须让所有消费者都消费到相同的消息。采用动态生成一个id附加到配置的group.id上，实现每个consumer都是一个group，来实现发布订阅的模式。
        group.id: L2CacheConsumerGroup
        # 自动提交offset（默认true）
        enable.auto.commit: true
        # 自动提交间隔
        auto.commit.interval.ms: 1000
        # key反序列化处理器
        key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
        # value反序列化处理器
        value.deserializer: org.apache.kafka.common.serialization.StringDeserializer
        # 设置消费的位置
        auto.offset.reset: latest
        # 设置一次最大拉取的消息条数（默认500）
        max.poll.records: 10
        # 设置poll最大时间间隔（默认3s）
        max.poll.interval.ms: 3000
