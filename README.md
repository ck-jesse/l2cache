# L2Cache 分布式二级缓存框架

[![Maven Central](https://img.shields.io/maven-central/v/io.github.ck-jesse/l2cache-core?color=green)](https://search.maven.org/search?q=g:io.github.ck-jesse%20AND%20a:l2cache-core)
[![Crates.io](https://img.shields.io/crates/l/ap)](https://www.apache.org/licenses/LICENSE-2.0.html)

# 一、简介

L2Cache 是一个基于`内存`、 `Redis` 、 `Spring Cache` 实现的满足高并发场景下的分布式二级缓存框架。

L2Cache 并没有重复造轮子，它只是将目前市面上比较成熟、经得起考验的框架组合起来，封装屏蔽了复杂的缓存操作和实现原理，最终给开发者留出了一个简单易懂和易维护的分布式缓存开发工具。

# 二、如何使用
- [如何使用L2Cache](https://blog.csdn.net/icansoicrazy/article/details/125097730)

# 三、核心原理
- [L2Cache核心原理解析](https://blog.csdn.net/icansoicrazy/article/details/131959016)

# 四、重要数据
**1、整体数据**
- 已在生产环境投产，目前主要应用在商品、优惠券、用户、营销等核心服务。
- 经历过多年双十一、双十二，以及`多次大促活动的流量洗礼`。
- 支撑公司单月`10亿GMV`
- 支撑全链路压测`35W QPS`
- 支撑500w日活


**2、下面提供一个【首页重构】时`商品中心`的压测数据，具体如下：**

| 环境 | 压测维度 | 最高QPS | 最低QPS | 平均RT  | 配置            |
|-----|------|-------|-------|---------|---------------|
| 单POD | 单接口  | 5k+   | 2k+   | 50ms内   | 1个pod，8c16g   |
| 集群  | 单接口  | 8w+   | 1w+   | 50ms内   | 25个pod，8c16g  |
| 集群  | 单链路  | 4.5w+ | 3.5w+ | 55ms内   | 25个pod，8c16g  |
| 集群  | 全链路  | 35w+  | -     | 55ms内   | 120个pod，8c16g |

特别注意：
- 由于依赖的资源较多，上面只列出了pod的配置，未列出诸如mq/redis/db/ingress/SLB等资源的配置。
- 不同接口的QPS不一样，因为业务复杂度和实现逻辑不一样。
- 压测是对系统的一种整体考量，链路中的任何环节，都对压测有致命的影响。
- 链路的压测，分为单链路和混合链路。其中，全链路是一种混合链路的压测场景。
- 上述QPS是在系统的各个指标处于稳定状态的压测值，如果极限施压QPS会更高。


# 五、核心功能
- **支持多种缓存类型：** 一级缓存、二级缓存、混合缓存
- **解决痛点问题：** 缓存击穿、缓存穿透等
- **动态缓存配置：** 支持动态调整混合缓存下的缓存类型，支持热key的手动配置
- **缓存一致性保证：** 通过消息通知的方式来保证集群环境下一级缓存的一致性
- **自动热key探测：** 自动识别热key并缓存到一级缓存
- **支持缓存批量操作：** 支持分页的批量获取、批量删除等
- **定义通用缓存层：** 承上启下，简化业务开发，规整业务代码
- **多redis实例支持：** 支持cacheName维度设置不同的redis实例

## **1、同其他开源框架的对比**

| 核心功能       | JetCache（阿里）                        | J2Cache（OSChina）                    | L2Cache                              |
| -------------- | ------------------------------------ | ------------------------------------ | ------------------------------------ |
| 支持的缓存类型 | 一级缓存<br />二级缓存<br />混合缓存 | 一级缓存<br />二级缓存<br />混合缓存 | 一级缓存<br />二级缓存<br />混合缓存 |
| 解决的痛点问题 | 缓存击穿<br />缓存穿透               | 缓存击穿<br />缓存穿透               | 缓存击穿<br />缓存穿透               |
| 缓存一致性保证 | 支持                                 | 支持                                 | 支持                                 |
| 动态缓存配置   | 不支持                               | 不支持                               | 支持                                 |
| 自动热key探测  | 不支持                               | 不支持                               | 支持                                 |
| 缓存批量操作   | 不支持                               | 不支持                               | 支持                                 |
| 通用缓存层     | 不支持                               | 不支持                               | 支持                                 |
> 说明：上面表格的对比，数据正在整理中，后续会再校对一次。

- 从上面表格的对比可发现，`L2Cache` 的核心优势为三个点：`自动热key探测`、`缓存批量操作`、`通用缓存层`。
- 这三点优势是从实际业务开发中沉淀下来的能力，不仅解决了实现多级缓存的复杂性问题，还进一步屏蔽了业务维度的缓存操作的复杂性。
- 这样一来，原本需要资深开发者才能开发的功能，现在高级和中级开发者，甚至初级开发者都能轻松、高效、高质地进行开发。
- 如果在实际业务开发中，你也遇到开发难度高，难以维护，难以扩展的痛点问题，建议可以试试L2Cache。`反正接入成本低，试试又何妨？`



## **2、L2Cache 的二级缓存结构**

1、L1：一级缓存，内存缓存，支持 `Caffeine` 和 `Guava Cache`。

2、L2：二级缓存，集中式缓存，支持 `Redis`。

3、混合缓存，指支持同时使用一级缓存和二级缓存。

由于大量的缓存读取会导致 `L2` 的网络成为整个系统的瓶颈，因此 `L1` 的目标是降低对 `L2` 的读取次数。避免使用独立缓存系统所带来的网络IO开销问题。`L2` 可以避免应用重启后导致的 `L1`数据丢失的问题，同时无需担心`L1`会增加太多的内存消耗，因为你可以设置 `L1`中缓存数据的数量。

 **说明：**


> `L2Cache` 满足CAP定理中的AP，也就是满足可用性和分区容错性，至于C(一致性)因为缓存的特性所以无法做到强一致性，只能尽可能的去做到一致性，保证最终的一致。


## **3、关键点**

支持根据配置`缓存类型`来灵活的组合使用不同的Cache。

1、支持只使用一级缓存`Caffeine` 和 `Guava Cache`。

2、支持只使用二级缓存`Redis`。

3、支持同时使用一二级缓存`Composite`。

## **4、必知**

若使用缓存，则必然可能出现不一致的情况。

也就是说，无法保证强一致性，只能保证最终一致性。

# 六、实战问题
- [l2cache热key探测-技术方案调研](https://blog.csdn.net/icansoicrazy/article/details/130885982)
- [关于缓存的几个常见问题分析和处理方案](https://blog.csdn.net/icansoicrazy/article/details/106635446)
- [实战-用户中心-l2cache-Caffeine的OOM异常分析](https://blog.csdn.net/icansoicrazy/article/details/108923992)
- [实战-用户中心-还原并验证使用caffeine出现频繁gc和oom的场景](https://blog.csdn.net/icansoicrazy/article/details/108934105)
- [实战-商品中心-Redis集群版超出最大内存限制异常](https://blog.csdn.net/icansoicrazy/article/details/108810679)
- [实战-商品中心-l2cache高并发场景下出现OOM的分析和优化方案](https://blog.csdn.net/icansoicrazy/article/details/112274052)
- [实战-商品中心-l2cache中caffeine.getIfPresent()仅仅获取缓存，但触发了数据加载，导致被设置为NullValue的问题分析](https://blog.csdn.net/icansoicrazy/article/details/125096876)



# 七、鼓励与帮助
如果 l2cache 对您有所帮助，不妨右上角点点 `Star` 或者`任意赞赏`支持。

您的 `Star` 或 `赞赏` 将会给我带来更多动力。

最后，欢迎你 Fork PR 成为项目贡献者。

# 八、联系方式
微信：chenck1112

![weixin](https://gitee.com/ck-jesse/l2cache/raw/master/img/weixin.jpg)


# 九、已知用户
按照注册顺序，欢迎更多访问公司在[#26](https://github.com/ck-jesse/l2cache/issues/26)注册（仅限开源用户）。
